---
title: Rabobank IT Service Management
description: IT service management logs from Rabobank Group ICT and related questions.
---

import ImplementationDisclaimer from '../../../components/ImplementationDisclaimer.astro';

This challenge provides a real-life event log from Rabobank Group ICT. The data relates to ITIL-based service management processes, specifically focusing on how software releases (planned changes) impact the workload of the Service Desk and IT Operations.

The dataset consists of anonymous records from the HP Service Manager tool. The information is provided in CSV format, organized by different ITIL processes:

* **Interaction Records:** Initial contacts with the service desk.
* **Incident Records:** Specific service disruptions.
* **Change Records:** Information regarding planned software releases or infrastructure changes.
* **Incident Activity Records:** A detailed log of activities specifically related to the Incident cases.

## Summary Statistics

| Metric | Dataset | Value |
| --- | --- | --- |
| Number of events | Interaction Records | 147,004 |
| Number of events | Incident Activity Records | 466,737 |
| Number of events | Change Records | 30,275 |
| Number of cases | Interaction Records | 140,338 |
| Number of cases | Incident Activity Records | 46,616 |
| Number of cases | Change Records | 18,000 |
| Filesize | Interaction Records | 21.9 MB |
| Filesize | Incident Activity Records | 39.2 MB |
| Filesize | Change Records | 6.7 MB |
| Filesize | Incident Records | 14.3 MB |

## Resource Links
The dataset is hosted at the 3TU datacenter. 

* **[Full Collection (DOI)](https://doi.org/10.4121/uuid:c3e5d162-0cfd-4bb0-bd82-af5268819c35)**
* **Data Files:**
    * [Change Records](https://doi.org/10.4121/uuid:d5ccb355-ca67-480f-8739-289b9b593aaf)
    * [Incident Records](https://doi.org/10.4121/uuid:3cfa2260-f5c5-44be-afe1-b70d35288d6d)
    * [Interaction Records](https://doi.org/10.4121/uuid:3d5ae0ce-198c-4b5c-b0f9-60d3035d07bf)
    * [Incident Activity Records](https://doi.org/10.4121/uuid:86977bac-f874-49cf-8337-80f26bf5d2ef)
* **Documentation:** [Quick Reference Guide](https://ais.win.tue.nl/bpi/2014/quick_reference_guide.pdf)

## Challenge Questions
The process owner is specifically interested in the following:

1.  **Identification of Impact-patterns:** Is there a correlation between the implementation of a change and the volume of closed interactions or incidents?
2.  **Pattern Parameters:** For the identified impact-patterns:
    * What is the average period required to return to a steady state?
    * What is the average increase or decrease in Closed Interactions once a new steady state is reached?
3.  **Average Steps to Resolution:** Is the service level (measured by steps to resolution) maintained or improved following a change implementation?
4.  **Predictive Modeling:** Can a model be designed to predict the workload impact of future software releases on the Service Desk?

## Implementation Considerations

<ImplementationDisclaimer />

1. **Temporal proximity as causality:** Impacts can be inferred by co-occurrence within a fixed window on the same service component (SC), but this treats coincidence as cause. Example: an incident on SC-42 within 3 days of a change might be unrelated to that change.

2. **Isolating “clean” changes:** Analyses may choose to selectively exclude changes that occur close together on the same service component to avoid interference. Example: filtering out any change within 3 days of another removes high-velocity systems from the sample.

3. **Definition of steady state:** Steady-state may be defined as activity within a statistical band (e.g., median, standard deviation) for a fixed interval. Example: a consistently noisy service could still be classified as “steady” by variance rules.

4. **Effort and complexity proxies:** Handling time and number of steps can be treated as proxies for effort and complexity, but they depend on logging practices. Example: a 50-day “handle time” may actually reflect waiting time rather than active work.

5. **Favourability labels from volume trends alone:** Impact patterns may be labeled favourable/unfavourable based on ticket volume changes alone. Example: fewer incidents after a change could represent truly improved stability, or falsely improved stability owing to a reporting outage.

6. **Working-hours normalization:** Time calculations may exclude nights/weekends. Example: a Friday-night outage may appear shorter if only 07:00–18:00, Mon–Fri is counted.

7. **Truncating edge effects:** The tail of the dataset may be removed to avoid open cases bias. Example: dropping the final 17 days improves closure completeness but removes recent change impacts.